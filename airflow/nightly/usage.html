<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Usage :: Stackable Documentation</title>
    <link rel="canonical" href="https://docs.stackable.tech/airflow/stable/usage.html">
    <meta name="generator" content="Antora 3.1.0">
    <link rel="stylesheet" href="../../_/css/site.css">
    <script>var uiRootPath = '../../_'</script>
    <link rel="icon" href="../../_/img/favicon.png" type="image/png">
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="container">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://stackable.tech"><img src="../../_/img/stackable-logo.png"></a>
      <a class="navbar-item documentation-link" href="https://docs.stackable.tech">Documentation</a>
      <div class="navbar-item search hide-for-print">
        <div id="search-field" class="field">
          <input id="search-input" type="text" placeholder="Search...">
        </div>
      </div>
      <button class="navbar-burger" data-target="navbar-sub">
        <span></span>
        <span></span>
        <span></span>
      </button>
      <a href="https://www.stackable.tech/contact/" class="button pull-right">Contact Us</a>
    </div>
      <div id="topbar-nav" class="navbar-menu">
      </div>
      </div>
    </nav>
    <nav id="navbar-sub" class="navbar-sub">
      <div class="container">
        <a class="navbar-sub-item" href="../../home/stable/index.html">Home</a>
<a class="navbar-sub-item" href="../../home/stable/getting_started.html">Getting Started</a>
<a class="navbar-sub-item" href="../../home/stable/concepts/index.html">Concepts</a>
<a class="navbar-sub-item" href="../../home/stable/tutorials/end-to-end_data_pipeline_example.html">Tutorials</a>
<a class="navbar-sub-item" href="../../stackablectl/stable/index.html">stackablectl</a>
<div class="navbar-sub-item drop-down">
    Operators
    <div class="drop-down-content">
        <a class="drop-down-item" href="../../home/stable/operators/index.html">Overview</a>
        <a class="drop-down-item" href="../stable/index.html">Apache Airflow</a>
        <a class="drop-down-item" href="../../druid/stable/index.html">Apache Druid</a>
        <a class="drop-down-item" href="../../hbase/stable/index.html">Apache HBase</a>
        <a class="drop-down-item" href="../../hdfs/stable/index.html">Apache Hadoop HDFS</a>
        <a class="drop-down-item" href="../../hive/stable/index.html">Apache Hive</a>
        <a class="drop-down-item" href="../../kafka/stable/index.html">Apache Kafka</a>
        <a class="drop-down-item" href="../../nifi/stable/index.html">Apache NiFi</a>
        <a class="drop-down-item" href="../../spark-k8s/stable/index.html">Apache Spark on K8S</a>
        <a class="drop-down-item" href="../../superset/stable/index.html">Apache Superset</a>
        <a class="drop-down-item" href="../../trino/stable/index.html">Trino</a>
        <a class="drop-down-item" href="../../zookeeper/stable/index.html">Apache ZooKeeper</a>
        <a class="drop-down-item" href="../../opa/stable/index.html">OpenPolicyAgent</a>
        <a class="drop-down-item" href="../../commons-operator/stable/index.html">Commons</a>
        <a class="drop-down-item" href="../../secret-operator/stable/index.html">Secret</a>
        <a class="drop-down-item" href="../../listener-operator/stable/index.html">Listener</a>
    </div>
</div>
<a class="navbar-sub-item" href="../../home/stable/contributor/index.html">Contribute</a>

        <a class="arrow" href="javascript:document.querySelector('.navbar-sub').classList.toggle('open')">
          <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="arrow-right" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"></path></svg>
        </a>
      </div>
    </nav>
  </header>
<div class="body">
    <div class="container">
<div class="nav-container" data-component="airflow" data-version="nightly">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <div class="title-wrapper">
      <h3 class="title"><a href="index.html">Stackable Operator for Apache Airflow</a></h3>
      <div class="page-versions">
        <button class="version-menu-toggle" title="Show other versions of page">nightly</button>
        <div class="version-menu">
          <a class="version is-current" href="usage.html">nightly</a>
          <a class="version" href="../stable/usage.html">0.6</a>
          <a class="version" href="../0.5/usage.html">0.5</a>
          <a class="version" href="../0.4/usage.html">0.4</a>
          <a class="version" href="../0.3/usage.html">0.3</a>
        </div>
      </div>
    </div>
    <ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="getting_started/index.html">Getting started</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="getting_started/installation.html">Installation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="getting_started/first_steps.html">First steps</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="configuration.html">Configuration</a>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="usage.html">Usage</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Stackable Operator for Apache Airflow</span>
    <span class="version">nightly</span>
  </div>
  <ul class="components">
    <li class="component">
      <a class="title" href="../../commons-operator/stable/index.html">Stackable Commons Operator</a>
      <ul class="versions">
        <li class="version">
          <a href="../../commons-operator/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../commons-operator/stable/index.html">0.4</a>
        </li>
        <li class="version">
          <a href="../../commons-operator/0.3/index.html">0.3</a>
        </li>
        <li class="version">
          <a href="../../commons-operator/0.2/index.html">0.2</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../home/stable/index.html">Stackable Documentation</a>
      <ul class="versions">
        <li class="version">
          <a href="../../home/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../home/stable/index.html">22.11</a>
        </li>
        <li class="version">
          <a href="../../home/22.09/index.html">22.09</a>
        </li>
        <li class="version">
          <a href="../../home/22.06/index.html">22.06</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../listener-operator/stable/index.html">Stackable Listener Operator</a>
      <ul class="versions">
        <li class="version is-latest">
          <a href="../../listener-operator/stable/index.html">nightly</a>
        </li>
      </ul>
    </li>
    <li class="component is-current">
      <a class="title" href="../stable/index.html">Stackable Operator for Apache Airflow</a>
      <ul class="versions">
        <li class="version is-current">
          <a href="index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../stable/index.html">0.6</a>
        </li>
        <li class="version">
          <a href="../0.5/index.html">0.5</a>
        </li>
        <li class="version">
          <a href="../0.4/index.html">0.4</a>
        </li>
        <li class="version">
          <a href="../0.3/index.html">0.3</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../druid/stable/index.html">Stackable Operator for Apache Druid</a>
      <ul class="versions">
        <li class="version">
          <a href="../../druid/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../druid/stable/index.html">0.8</a>
        </li>
        <li class="version">
          <a href="../../druid/0.7/index.html">0.7</a>
        </li>
        <li class="version">
          <a href="../../druid/0.6/index.html">0.6</a>
        </li>
        <li class="version">
          <a href="../../druid/0.2/index.html">0.2</a>
        </li>
        <li class="version">
          <a href="../../druid/0.1/index.html">0.1</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../hbase/stable/index.html">Stackable Operator for Apache HBase</a>
      <ul class="versions">
        <li class="version">
          <a href="../../hbase/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../hbase/stable/index.html">0.5</a>
        </li>
        <li class="version">
          <a href="../../hbase/0.4/index.html">0.4</a>
        </li>
        <li class="version">
          <a href="../../hbase/0.3/index.html">0.3</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../hdfs/stable/index.html">Stackable Operator for Apache HDFS</a>
      <ul class="versions">
        <li class="version">
          <a href="../../hdfs/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../hdfs/stable/index.html">0.6</a>
        </li>
        <li class="version">
          <a href="../../hdfs/0.5/index.html">0.5</a>
        </li>
        <li class="version">
          <a href="../../hdfs/0.4/index.html">0.4</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../hive/stable/index.html">Stackable Operator for Apache Hive</a>
      <ul class="versions">
        <li class="version">
          <a href="../../hive/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../hive/stable/index.html">0.8</a>
        </li>
        <li class="version">
          <a href="../../hive/0.7/index.html">0.7</a>
        </li>
        <li class="version">
          <a href="../../hive/0.6/index.html">0.6</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../kafka/stable/index.html">Stackable Operator for Apache Kafka</a>
      <ul class="versions">
        <li class="version">
          <a href="../../kafka/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../kafka/stable/index.html">0.8</a>
        </li>
        <li class="version">
          <a href="../../kafka/0.7/index.html">0.7</a>
        </li>
        <li class="version">
          <a href="../../kafka/0.6/index.html">0.6</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../nifi/stable/index.html">Stackable Operator for Apache NiFi</a>
      <ul class="versions">
        <li class="version">
          <a href="../../nifi/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../nifi/stable/index.html">0.8</a>
        </li>
        <li class="version">
          <a href="../../nifi/0.7/index.html">0.7</a>
        </li>
        <li class="version">
          <a href="../../nifi/0.6/index.html">0.6</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../spark-k8s/stable/index.html">Stackable Operator for Apache Spark on Kubernetes</a>
      <ul class="versions">
        <li class="version">
          <a href="../../spark-k8s/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../spark-k8s/stable/index.html">0.6</a>
        </li>
        <li class="version">
          <a href="../../spark-k8s/0.5/index.html">0.5</a>
        </li>
        <li class="version">
          <a href="../../spark-k8s/0.4/index.html">0.4</a>
        </li>
        <li class="version">
          <a href="../../spark-k8s/0.3/index.html">0.3</a>
        </li>
        <li class="version">
          <a href="../../spark-k8s/0.2/index.html">0.2</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../superset/stable/index.html">Stackable Operator for Apache Superset</a>
      <ul class="versions">
        <li class="version">
          <a href="../../superset/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../superset/stable/index.html">0.7</a>
        </li>
        <li class="version">
          <a href="../../superset/0.6/index.html">0.6</a>
        </li>
        <li class="version">
          <a href="../../superset/0.5/index.html">0.5</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../zookeeper/stable/index.html">Stackable Operator for Apache ZooKeeper</a>
      <ul class="versions">
        <li class="version">
          <a href="../../zookeeper/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../zookeeper/stable/index.html">0.12</a>
        </li>
        <li class="version">
          <a href="../../zookeeper/0.11/index.html">0.11</a>
        </li>
        <li class="version">
          <a href="../../zookeeper/0.10/index.html">0.10</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../opa/stable/index.html">Stackable Operator for OPA</a>
      <ul class="versions">
        <li class="version">
          <a href="../../opa/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../opa/stable/index.html">0.11</a>
        </li>
        <li class="version">
          <a href="../../opa/0.10/index.html">0.10</a>
        </li>
        <li class="version">
          <a href="../../opa/0.9/index.html">0.9</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../trino/stable/index.html">Stackable Operator for Trino</a>
      <ul class="versions">
        <li class="version">
          <a href="../../trino/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../trino/stable/index.html">0.8</a>
        </li>
        <li class="version">
          <a href="../../trino/0.7/index.html">0.7</a>
        </li>
        <li class="version">
          <a href="../../trino/0.6/index.html">0.6</a>
        </li>
        <li class="version">
          <a href="../../trino/0.5/index.html">0.5</a>
        </li>
        <li class="version">
          <a href="../../trino/0.4/index.html">0.4</a>
        </li>
        <li class="version">
          <a href="../../trino/0.3/index.html">0.3</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../secret-operator/stable/index.html">Stackable Secret Operator</a>
      <ul class="versions">
        <li class="version">
          <a href="../../secret-operator/nightly/index.html">nightly</a>
        </li>
        <li class="version is-latest">
          <a href="../../secret-operator/stable/index.html">0.5</a>
        </li>
      </ul>
    </li>
    <li class="component">
      <a class="title" href="../../stackablectl/stable/index.html">stackablectl</a>
      <ul class="versions">
        <li class="version is-latest">
          <a href="../../stackablectl/stable/index.html">nightly</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../../home/stable/index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Stackable Operator for Apache Airflow</a></li>
    <li><a href="usage.html">Usage</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="https://github.com/stackabletech/airflow-operator/edit/main/docs/modules/ROOT/pages/usage.adoc">Edit this Page</a></div>
  </div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Usage</h1>
<div class="sect1">
<h2 id="_monitoring"><a class="anchor" href="#_monitoring"></a>Monitoring</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The managed Airflow instances are automatically configured to export Prometheus metrics. See
<a href="../../home/stable/operators/monitoring.html" class="xref page">Monitoring</a> for more details.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_configuration_environment_overrides"><a class="anchor" href="#_configuration_environment_overrides"></a>Configuration &amp; Environment Overrides</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The cluster definition also supports overriding configuration properties and environment variables, either per role or per role group, where the more specific override (role group) has precedence over the less specific one (role).</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Overriding certain properties which are set by operator (such as the HTTP port) can interfere with the operator and can lead to problems. Additionally, for Airflow it is recommended
that each component has the same configuration: not all components use each setting, but some things - such as external end-points - need to be consistent for things to work as expected.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_configuration_properties"><a class="anchor" href="#_configuration_properties"></a>Configuration Properties</h3>
<div class="paragraph">
<p>Airflow exposes an environment variable for every Airflow configuration setting, a list of which can be found in the <a href="https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html">Configuration Reference</a>.</p>
</div>
<div class="paragraph">
<p>Although Kubernetes can override these settings in one of two ways (Configuration overrides, or Environment Variable overrides), the affect is the same
and currently only the latter is implemented. This is described in the following section.</p>
</div>
</div>
<div class="sect2">
<h3 id="_environment_variables"><a class="anchor" href="#_environment_variables"></a>Environment Variables</h3>
<div class="paragraph">
<p>These can be set - or overwritten - at either the role level:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">webservers:
  envOverrides:
    AIRFLOW__WEBSERVER__AUTO_REFRESH_INTERVAL: "8"
  roleGroups:
    default:
      replicas: 1</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or per role group:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">webservers:
  roleGroups:
    default:
      envOverrides:
        AIRFLOW__WEBSERVER__AUTO_REFRESH_INTERVAL: "8"
      replicas: 1</code></pre>
</div>
</div>
<div class="paragraph">
<p>In both examples above we are replacing the default value of the UI DAG refresh (3s) with 8s. Note that all override property values must be strings.</p>
</div>
</div>
<div class="sect2">
<h3 id="_storage_for_data_volumes"><a class="anchor" href="#_storage_for_data_volumes"></a>Storage for data volumes</h3>
<div class="paragraph">
<p>The Airflow Operator currently does not support using <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes">PersistentVolumeClaims</a> for internal storage.</p>
</div>
</div>
<div class="sect2">
<h3 id="_resource_requests"><a class="anchor" href="#_resource_requests"></a>Resource Requests</h3>
<div class="paragraph">
<p>Stackable operators handle resource requests in a sligtly different manner than Kubernetes. Resource requests are defined on role or group level. See <a href="../../home/stable/concepts/roles-and-role-groups.html" class="xref page">Roles and role groups</a> for details on these concepts. On a role level this means that e.g. all workers will use the same resource requests and limits. This can be further specified on role group level (which takes priority to the role level) to apply different resources.</p>
</div>
<div class="paragraph">
<p>This is an example on how to specify CPU and memory resources using the Stackable <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Custom Resources</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: example.stackable.tech/v1alpha1
kind: ExampleCluster
metadata:
  name: example
spec:
  workers: # role-level
    config:
      resources:
        cpu:
          min: 300m
          max: 600m
        memory:
          limit: 3Gi
    roleGroups: # role-group-level
      resources-from-role: # role-group 1
        replicas: 1
      resources-from-role-group: # role-group 2
        replicas: 1
        config:
          resources:
            cpu:
              min: 400m
              max: 800m
            memory:
              limit: 4Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this case, the role group <code>resources-from-role</code> will inherit the resources specified on the role level. Resulting in a maximum of <code>3Gi</code> memory and <code>600m</code> CPU resources.</p>
</div>
<div class="paragraph">
<p>The role group <code>resources-from-role-group</code> has maximum of <code>4Gi</code> memory and <code>800m</code> CPU resources (which overrides the role CPU resources).</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
For Java products the actual used Heap memory is lower than the specified memory limit due to other processes in the Container requiring memory to run as well. Currently, 80% of the specified memory limits is passed to the JVM.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For memory only a limit can be specified, which will be set as memory request and limit in the Container. This is to always guarantee a Container the full amount memory during Kubernetes scheduling.</p>
</div>
<div class="paragraph">
<p>If no resource requests are configured explicitely, the operator uses the following defaults:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">workers:
  roleGroups:
    default:
      config:
        resources:
          cpu:
            min: '200m'
            max: "4"
          memory:
            limit: '2Gi'</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_initializing_the_airflow_database"><a class="anchor" href="#_initializing_the_airflow_database"></a>Initializing the Airflow database</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Airflow comes with a default embedded database (intended only for standalone mode): for cluster usage an external database is used such as PostgreSQL, described above. This database must be initialized with an airflow schema and the Admin user defined in the airflow credentials <code>Secret</code>. This is done the first time the cluster is created and can take a few moments.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_using_airflow"><a class="anchor" href="#_using_airflow"></a>Using Airflow</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When the Airflow cluster is created and the database is initialized, Airflow can be opened in the
browser.</p>
</div>
<div class="paragraph">
<p>The Airflow port which defaults to <code>8080</code> can be forwarded to the local host:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl port-forward airflow-webserver-default-0 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then it can be opened in the browser with <code><a href="http://localhost:8080" class="bare">http://localhost:8080</a></code>.</p>
</div>
<div class="paragraph">
<p>Enter the admin credentials from the Kubernetes secret:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/airflow_login.png" alt="Login screen of Airflow">
</div>
</div>
<div class="paragraph">
<p>If the examples were loaded then some dashboards are already available:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/airflow_dags.png" alt="Airflow UI showing example DAGs">
</div>
</div>
<div class="paragraph">
<p>Click on an example DAG and then invoke the job: if the scheduler is correctly set up then the job
will run and the job tree will update automatically:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/airflow_running.png" alt="Airflow UI showing a running DAG">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_authentication"><a class="anchor" href="#_authentication"></a>Authentication</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Every user has to authenticate themselves before using Airflow and there are several ways of doing this.</p>
</div>
<div class="sect2">
<h3 id="_webinterface"><a class="anchor" href="#_webinterface"></a>Webinterface</h3>
<div class="paragraph">
<p>The default setting is to view and manually set up users via the Webserver UI. Note the blue "+" button where users can be added directly:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/airflow_security.png" alt="Airflow Security menu">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ldap"><a class="anchor" href="#_ldap"></a>LDAP</h3>
<div class="paragraph">
<p>Airflow supports authentication of users against an LDAP server.
Have a look at <a href="https://github.com/stackabletech/airflow-operator/blob/main/examples/simple-airflow-cluster-ldap.yaml">the LDAP example</a> and the general <a href="../../commons-operator/stable/authenticationclass.html" class="xref page">Stackable Authentication</a> documentation on how to set it up.
In general, it requires you to specify a <a href="../../commons-operator/stable/authenticationclass.html" class="xref page"><code>AuthenticationClass</code></a> which is used to authenticate the users. In the example below we assign all the users the <code>Admin</code> role once they log into Airflow:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: airflow.stackable.tech/v1alpha1
kind: AirflowCluster
metadata:
  name: airflow-with-ldap
spec:
  version: 2.4.1-stackable0.4.0
  [...]
  authenticationConfig:
    authenticationClass: airflow-with-ldap-ldap
    userRegistrationRole: Admin</code></pre>
</div>
</div>
<div class="paragraph">
<p>The users and roles can be viewed as before in the Webserver UI, but note that the blue "+" button is not available when authenticating against LDAP:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/airflow_security_ldap.png" alt="Airflow Security menu">
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_authorization"><a class="anchor" href="#_authorization"></a>Authorization</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Airflow Webserver delegates the <a href="https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.html">handling of user access control</a> to <a href="https://flask-appbuilder.readthedocs.io/en/latest/security.html">Flask AppBuilder</a>.</p>
</div>
<div class="sect2">
<h3 id="_webinterface_2"><a class="anchor" href="#_webinterface_2"></a>Webinterface</h3>
<div class="paragraph">
<p>You can view, add to, and assign the roles displayed in the Airflow Webserver UI to existing users.</p>
</div>
</div>
<div class="sect2">
<h3 id="_ldap_2"><a class="anchor" href="#_ldap_2"></a>LDAP</h3>
<div class="paragraph">
<p>Airflow supports assigning roles to users based on their LDAP group membership
, though this is not yet supported by the Stackable operator. Currently, all the users logging in via LDAP get assigned the same role which you can configure via the attribute <code>authenticationConfig.userRegistrationRole</code> on the <code>AirflowCluster</code> object.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_monitoring_2"><a class="anchor" href="#_monitoring_2"></a>Monitoring</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The managed Airflow instances are automatically configured to export Prometheus metrics. See
<a href="../../home/stable/operators/monitoring.html" class="xref page">Monitoring</a> for more details</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_mounting_dags"><a class="anchor" href="#_mounting_dags"></a>Mounting DAGs</h2>
<div class="sectionbody">
<div class="paragraph">
<p>DAGs can be mounted by using a <code>ConfigMap</code> or a <code>PersistentVolumeClaim</code>. This is best illustrated with an example of each, shown in the next section.</p>
</div>
<div class="sect2">
<h3 id="_via_configmap"><a class="anchor" href="#_via_configmap"></a>via <code>ConfigMap</code></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-dag <i class="conum" data-value="1"></i><b>(1)</b>
data:
  test_airflow_dag.py: | <i class="conum" data-value="2"></i><b>(2)</b>
    from datetime import datetime, timedelta
    from airflow import DAG
    from airflow.operators.bash import BashOperator
    from airflow.operators.dummy import DummyOperator

    with DAG(
        dag_id='test_airflow_dag',
        schedule_interval='0 0 * * *',
        start_date=datetime(2021, 1, 1),
        catchup=False,
        dagrun_timeout=timedelta(minutes=60),
        tags=['example', 'example2'],
        params={"example_key": "example_value"},
    ) as dag:
        run_this_last = DummyOperator(
            task_id='run_this_last',
        )

        # [START howto_operator_bash]
        run_this = BashOperator(
            task_id='run_after_loop',
            bash_command='echo 1',
        )
        # [END howto_operator_bash]

        run_this &gt;&gt; run_this_last

        for i in range(3):
            task = BashOperator(
                task_id='runme_' + str(i),
                bash_command='echo "{{ task_instance_key_str }}" &amp;&amp; sleep 1',
            )
            task &gt;&gt; run_this

        # [START howto_operator_bash_template]
        also_run_this = BashOperator(
            task_id='also_run_this',
            bash_command='echo "run_id={{ run_id }} | dag_run={{ dag_run }}"',
        )
        # [END howto_operator_bash_template]
        also_run_this &gt;&gt; run_this_last

    # [START howto_operator_bash_skip]
    this_will_skip = BashOperator(
        task_id='this_will_skip',
        bash_command='echo "hello world"; exit 99;',
        dag=dag,
    )
    # [END howto_operator_bash_skip]
    this_will_skip &gt;&gt; run_this_last

    if __name__ == "__main__":
        dag.cli()</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>---
apiVersion: airflow.stackable.tech/v1alpha1
kind: AirflowCluster
metadata:
  name: airflow
spec:
  version: 2.4.1-stackable0.4.0
  statsdExporterVersion: v0.22.4
  executor: CeleryExecutor
  loadExamples: false
  exposeConfig: false
  credentialsSecret: simple-airflow-credentials
  volumes:
    - name: cm-dag <i class="conum" data-value="3"></i><b>(3)</b>
      configMap:
        name: cm-dag <i class="conum" data-value="4"></i><b>(4)</b>
  volumeMounts:
    - name: cm-dag <i class="conum" data-value="5"></i><b>(5)</b>
      mountPath: /dags/test_airflow_dag.py <i class="conum" data-value="6"></i><b>(6)</b>
      subPath: test_airflow_dag.py <i class="conum" data-value="7"></i><b>(7)</b>
  webservers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW__CORE__DAGS_FOLDER: "/dags" <i class="conum" data-value="8"></i><b>(8)</b>
        replicas: 1
  workers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW__CORE__DAGS_FOLDER: "/dags" <i class="conum" data-value="8"></i><b>(8)</b>
        replicas: 2
  schedulers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW__CORE__DAGS_FOLDER: "/dags" <i class="conum" data-value="8"></i><b>(8)</b>
        replicas: 1</pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The name of the configuration map</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The name of the DAG (this is a renamed copy of the <code>example_bash_operator.py</code> from the Airflow examples)</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The volume backed by the configuration map</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The name of the configuration map referenced by the Airflow cluster</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>The name of the mounted volume</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>The path of the mounted resource. Note that should map to a single DAG.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>The resource has to be defined using <code>subPath</code>: this is to prevent the versioning of configuration map elements which may cause a conflict with how Airflow propagates DAGs between its components.</td>
</tr>
<tr>
<td><i class="conum" data-value="8"></i><b>8</b></td>
<td>If the mount path described above is anything other than the standard location (the default is <code>$AIRFLOW_HOME/dags</code>), then the location should be defined using the relevant environment variable.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The advantage of this approach is that a DAG can be provided "in-line", as it were. This becomes cumbersome when multiple DAGs are to be made available in this way, as each one has to be mapped individually. For multiple DAGs it is probably easier to expose them all via a mounted volume, which is shown below.</p>
</div>
</div>
<div class="sect2">
<h3 id="_via_persistentvolumeclaim"><a class="anchor" href="#_via_persistentvolumeclaim"></a>via PersistentVolumeclaim</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-airflow <i class="conum" data-value="1"></i><b>(1)</b>
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
apiVersion: batch/v1
kind: Job <i class="conum" data-value="2"></i><b>(2)</b>
metadata:
  name: airflow-dags
spec:
  template:
    spec:
      restartPolicy: Never
      volumes:
        - name: external-dags <i class="conum" data-value="3"></i><b>(3)</b>
          persistentVolumeClaim:
            claimName: pvc-airflow <i class="conum" data-value="4"></i><b>(4)</b>
      initContainers:
        - name: dest-dir
          image: docker.stackable.tech/stackable/tools:0.2.0-stackable0
          env:
            - name: DEST_DIR
              value: "/stackable/externals"
          command:
            [
              "bash",
              "-x",
              "-c",
              "mkdir -p $DEST_DIR &amp;&amp; chown stackable:stackable ${DEST_DIR} &amp;&amp; chmod -R a=,u=rwX,g=rwX ${DEST_DIR}",
            ]
          securityContext:
            runAsUser: 0
          volumeMounts:
            - name: external-dags <i class="conum" data-value="5"></i><b>(5)</b>
              mountPath: /stackable/externals <i class="conum" data-value="6"></i><b>(6)</b>
      containers:
        - name: airflow-dags
          image: docker.stackable.tech/stackable/tools:0.2.0-stackable0
          env:
            - name: DEST_DIR
              value: "/stackable/externals"
          command: <i class="conum" data-value="7"></i><b>(7)</b>
            [
              "bash",
              "-x",
              "-c",
              "curl -L  https://raw.githubusercontent.com/apache/airflow/2.4.1/airflow/example_dags/example_bash_operator.py \
              -o ${DEST_DIR}/example_bash_operator.py &amp;&amp; \
              curl -L  https://raw.githubusercontent.com/apache/airflow/2.4.1/airflow/example_dags/example_complex.py \
              -o ${DEST_DIR}/example_complex.py &amp;&amp; \
              curl -L  https://raw.githubusercontent.com/apache/airflow/2.4.1/airflow/example_dags/example_branch_datetime_operator.py \
              -o ${DEST_DIR}/example_branch_datetime_operator.py",
            ]
          volumeMounts:
            - name: external-dags <i class="conum" data-value="5"></i><b>(5)</b>
              mountPath: /stackable/externals <i class="conum" data-value="6"></i><b>(6)</b></code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: airflow.stackable.tech/v1alpha1
kind: AirflowCluster
metadata:
  name: airflow
spec:
  version: 2.2.4-python39-stackable0.3.0
  statsdExporterVersion: v0.22.4
  executor: CeleryExecutor
  loadExamples: false
  exposeConfig: false
  credentialsSecret: simple-airflow-credentials
  volumes:
    - name: external-dags <i class="conum" data-value="8"></i><b>(8)</b>
      persistentVolumeClaim:
        claimName: pvc-airflow <i class="conum" data-value="9"></i><b>(9)</b>
  volumeMounts:
    - name: external-dags <i class="conum" data-value="10"></i><b>(10)</b>
      mountPath: /stackable/external-dags <i class="conum" data-value="11"></i><b>(11)</b>
  webservers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW__CORE__DAGS_FOLDER: "/stackable/external-dags" <i class="conum" data-value="12"></i><b>(12)</b>
        replicas: 1
  workers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW__CORE__DAGS_FOLDER: "/stackable/external-dags" <i class="conum" data-value="12"></i><b>(12)</b>
        replicas: 2
  schedulers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW__CORE__DAGS_FOLDER: "/stackable/external-dags" <i class="conum" data-value="12"></i><b>(12)</b>
        replicas: 1</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The name of the <code>PersistentVolumeClaim</code> that references the PV</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Job used to populate the <code>PersistentVolumeClaim</code> with DAG files</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The volume name that will be mounted as a target for the DAG files</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Defines the <code>Volume</code> backed by the PVC, local to the Custom Resource</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>The <code>VolumeMount</code> used by the Custom Resource</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>The path for the <code>VolumeMount</code></td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>The command used to access/download the DAG files to a specified location</td>
</tr>
<tr>
<td><i class="conum" data-value="8"></i><b>8</b></td>
<td>The <code>Volume</code> used by this Custom Resource</td>
</tr>
<tr>
<td><i class="conum" data-value="9"></i><b>9</b></td>
<td>The <code>PersistentVolumeClaim</code> that backs this <code>Volume</code></td>
</tr>
<tr>
<td><i class="conum" data-value="10"></i><b>10</b></td>
<td>The <code>VolumeMount</code> referencing the <code>Volume</code> in the previous step</td>
</tr>
<tr>
<td><i class="conum" data-value="11"></i><b>11</b></td>
<td>The path where this <code>Volume</code> is located for each role (webserver, worker, scheduler)</td>
</tr>
<tr>
<td><i class="conum" data-value="12"></i><b>12</b></td>
<td>If the mount path described above is anything other than the standard location (the default is <code>$AIRFLOW_HOME/dags</code>), then the location should be defined using the relevant environment variable.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_node_selection"><a class="anchor" href="#_node_selection"></a>Node selection</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Airflow expects that all its components (webserver, scheduler, workers etc.) have access to the DAG folder. If this is mounted via a PersistentVolumeClaim, then the permissible <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes">access modes</a> on that claim may require that a specific node is selected. This can be done by providing a label-match as shown below:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">  workers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW__CORE__DAGS_FOLDER: "/stackable/external-dags"
        replicas: 1
        selector:
          matchLabels:
            node: "2"</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_applying_custom_resources"><a class="anchor" href="#_applying_custom_resources"></a>Applying Custom Resources</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Airflow can be used to apply custom resources from within a cluster. An example of this could be a SparkApplication job that is to be triggered by Airflow. The steps below describe how this can be done.</p>
</div>
<div class="sect2">
<h3 id="_define_an_in_cluster_kubernetes_connection"><a class="anchor" href="#_define_an_in_cluster_kubernetes_connection"></a>Define an in-cluster Kubernetes connection</h3>
<div class="paragraph">
<p>An in-cluster connection can either be created from within the Webserver UI (note that the "in cluster configuration" box is ticked):</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/airflow_connection_ui.png" alt="Airflow Connections">
</div>
</div>
<div class="paragraph">
<p>Alternatively, the connection can be <a href="https://airflow.apache.org/docs/apache-airflow/stable/howto/connection.html">defined</a> by an environment variable in URI format:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">AIRFLOW_CONN_KUBERNETES_IN_CLUSTER: "kubernetes://?__extra__=%7B%22extra__kubernetes__in_cluster%22%3A+true%2C+%22extra__kubernetes__kube_config%22%3A+%22%22%2C+%22extra__kubernetes__kube_config_path%22%3A+%22%22%2C+%22extra__kubernetes__namespace%22%3A+%22%22%7D"</code></pre>
</div>
</div>
<div class="paragraph">
<p>This can be supplied directly in the custom resource for all roles (Airflow expects configuration to be common across components):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: airflow.stackable.tech/v1alpha1
kind: AirflowCluster
metadata:
  name: airflow
spec:
  version: 2.2.3-python38-stackable0.3.0
  statsdExporterVersion: v0.22.4
  executor: CeleryExecutor
  loadExamples: false
  exposeConfig: false
  credentialsSecret: simple-airflow-credentials
  webservers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW_CONN_KUBERNETES_IN_CLUSTER: "kubernetes://?__extra__=%7B%22extra__kubernetes__in_cluster%22%3A+true%2C+%22extra__kubernetes__kube_config%22%3A+%22%22%2C+%22extra__kubernetes__kube_config_path%22%3A+%22%22%2C+%22extra__kubernetes__namespace%22%3A+%22%22%7D"
        replicas: 1
  workers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW_CONN_KUBERNETES_IN_CLUSTER: "kubernetes://?__extra__=%7B%22extra__kubernetes__in_cluster%22%3A+true%2C+%22extra__kubernetes__kube_config%22%3A+%22%22%2C+%22extra__kubernetes__kube_config_path%22%3A+%22%22%2C+%22extra__kubernetes__namespace%22%3A+%22%22%7D"
        replicas: 1
  schedulers:
    roleGroups:
      default:
        envOverrides:
          AIRFLOW_CONN_KUBERNETES_IN_CLUSTER: "kubernetes://?__extra__=%7B%22extra__kubernetes__in_cluster%22%3A+true%2C+%22extra__kubernetes__kube_config%22%3A+%22%22%2C+%22extra__kubernetes__kube_config_path%22%3A+%22%22%2C+%22extra__kubernetes__namespace%22%3A+%22%22%7D"
        replicas: 1</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_define_a_cluster_role_for_airflow_to_create_sparkapplication_resources"><a class="anchor" href="#_define_a_cluster_role_for_airflow_to_create_sparkapplication_resources"></a>Define a cluster role for Airflow to create SparkApplication resources</h3>
<div class="paragraph">
<p>Airflow cannot create or access SparkApplication resources by default - a cluster role is required for this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: airflow-spark-clusterrole
rules:
- apiGroups:
  - spark.stackable.tech
  resources:
  - sparkapplications
  verbs:
  - create
  - get</code></pre>
</div>
</div>
<div class="paragraph">
<p>and a corresponding cluster role binding:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: airflow-spark-clusterrole-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: airflow-spark-clusterrole
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: system:serviceaccounts</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_dag_code"><a class="anchor" href="#_dag_code"></a>DAG code</h3>
<div class="paragraph">
<p>Now for the DAG itself. The job to be started is a simple Spark job that calculates the value of pi:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
metadata:
  name: pyspark-pi
  namespace: default
spec:
  version: "1.0"
  sparkImage: docker.stackable.tech/stackable/pyspark-k8s:3.3.0-stackable0.1.0
  mode: cluster
  mainApplicationFile: local:///stackable/spark/examples/src/main/python/pi.py
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
  executor:
    cores: 1
    instances: 3
    memory: "512m"</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will called from within a DAG by using the connection that was defined earlier. It will be wrapped by the <code>KubernetesHook</code> that the Airflow Kubernetes provider makes available. There are two classes that are used to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>start the job</p>
</li>
<li>
<p>monitor the status of the job</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These are written in-line in the python code below, though this is just to make it clear how the code is used (the classes <code>SparkKubernetesOperator</code> and <code>SparkKubernetesSensor</code> will be used for all custom resources and thus are best defined as separate python files that the DAG would reference).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

"""Example DAG demonstrating how to apply a Kubernetes Resource from Airflow running in-cluster"""

from datetime import datetime, timedelta
from airflow import DAG
from typing import TYPE_CHECKING, Optional, Sequence, Dict
from kubernetes import client
from airflow.exceptions import AirflowException
from airflow.sensors.base import BaseSensorOperator
from airflow.models import BaseOperator
from airflow.providers.cncf.kubernetes.hooks.kubernetes import KubernetesHook

if TYPE_CHECKING:
    from airflow.utils.context import Context


class SparkKubernetesOperator(BaseOperator):  <i class="conum" data-value="1"></i><b>(1)</b>
    """
    Creates a SparkApplication resource in kubernetes:
    :param application_file: Defines a 'SparkApplication' custom resource as either a
        path to a '.yaml' file, '.json' file, YAML string or JSON string.
    :param namespace: kubernetes namespace for the SparkApplication
    :param kubernetes_conn_id: The :ref:`kubernetes connection id &lt;howto/connection:kubernetes&gt;`
        for the Kubernetes cluster.
    :param api_group: SparkApplication API group
    :param api_version: SparkApplication API version
    """

    template_fields: Sequence[str] = ('application_file', 'namespace')
    template_ext: Sequence[str] = ('.yaml', '.yml', '.json')
    ui_color = '#f4a460'

    def __init__(
        self,
        *,
        application_file: str,
        namespace: Optional[str] = None,
        kubernetes_conn_id: str = 'kubernetes_in_cluster',  <i class="conum" data-value="2"></i><b>(2)</b>
        api_group: str = 'spark.stackable.tech',
        api_version: str = 'v1alpha1',
        **kwargs,
    ) -&gt; None:
        super().__init__(**kwargs)
        self.application_file = application_file
        self.namespace = namespace
        self.kubernetes_conn_id = kubernetes_conn_id
        self.api_group = api_group
        self.api_version = api_version
        self.plural = "sparkapplications"

    def execute(self, context: 'Context'):
        hook = KubernetesHook(conn_id=self.kubernetes_conn_id)
        self.log.info("Creating SparkApplication...")
        response = hook.create_custom_object(
            group=self.api_group,
            version=self.api_version,
            plural=self.plural,
            body=self.application_file,
            namespace=self.namespace,
        )
        return response


class SparkKubernetesSensor(BaseSensorOperator):  <i class="conum" data-value="3"></i><b>(3)</b>
    """
    Monitors a SparkApplication resource in kubernetes:
    :param application_name: SparkApplication resource name
    :param namespace: the kubernetes namespace where the SparkApplication reside in
    :param kubernetes_conn_id: The :ref:`kubernetes connection&lt;howto/connection:kubernetes&gt;`
        to Kubernetes cluster.
    :param attach_log: determines whether logs for driver pod should be appended to the sensor log
    :param api_group: SparkApplication API group
    :param api_version: SparkApplication API version
    """

    template_fields = ("application_name", "namespace")
    FAILURE_STATES = ("Failed", "Unknown")
    SUCCESS_STATES = ("Succeeded")

    def __init__(
            self,
            *,
            application_name: str,
            attach_log: bool = False,
            namespace: Optional[str] = None,
            kubernetes_conn_id: str = 'kubernetes_in_cluster',  <i class="conum" data-value="2"></i><b>(2)</b>
            api_group: str = 'spark.stackable.tech',
            api_version: str = 'v1alpha1',
            poke_interval: float = 60,
            **kwargs,
    ) -&gt; None:
        super().__init__(**kwargs)
        self.application_name = application_name
        self.attach_log = attach_log
        self.namespace = namespace
        self.kubernetes_conn_id = kubernetes_conn_id
        self.hook = KubernetesHook(conn_id=self.kubernetes_conn_id)
        self.api_group = api_group
        self.api_version = api_version
        self.poke_interval = poke_interval

    def _log_driver(self, application_state: str, response: dict) -&gt; None:
        if not self.attach_log:
            return
        status_info = response["status"]
        if "driverInfo" not in status_info:
            return
        driver_info = status_info["driverInfo"]
        if "podName" not in driver_info:
            return
        driver_pod_name = driver_info["podName"]
        namespace = response["metadata"]["namespace"]
        log_method = self.log.error if application_state in self.FAILURE_STATES else self.log.info
        try:
            log = ""
            for line in self.hook.get_pod_logs(driver_pod_name, namespace=namespace):
                log += line.decode()
            log_method(log)
        except client.rest.ApiException as e:
            self.log.warning(
                "Could not read logs for pod %s. It may have been disposed.\n"
                "Make sure timeToLiveSeconds is set on your SparkApplication spec.\n"
                "underlying exception: %s",
                driver_pod_name,
                e,
            )

    def poke(self, context: Dict) -&gt; bool:
        self.log.info("Poking: %s", self.application_name)
        response = self.hook.get_custom_object(
            group=self.api_group,
            version=self.api_version,
            plural="sparkapplications",
            name=self.application_name,
            namespace=self.namespace,
        )
        try:
            application_state = response["status"]["phase"]
        except KeyError:
            self.log.debug(f"SparkApplication status could not be established: {response}")
            return False
        if self.attach_log and application_state in self.FAILURE_STATES + self.SUCCESS_STATES:
            self._log_driver(application_state, response)
        if application_state in self.FAILURE_STATES:
            raise AirflowException(f"SparkApplication failed with state: {application_state}")
        elif application_state in self.SUCCESS_STATES:
            self.log.info("SparkApplication ended successfully")
            return True
        else:
            self.log.info("SparkApplication is still in state: %s", application_state)
            return False


with DAG(  <i class="conum" data-value="4"></i><b>(4)</b>
    dag_id='sparkapp_dag',
    schedule_interval='0 0 * * *',
    start_date=datetime(2021, 1, 1),
    catchup=False,
    dagrun_timeout=timedelta(minutes=60),
    tags=['example'],
    params={"example_key": "example_value"},
) as dag:

    t1 = SparkKubernetesOperator(  <i class="conum" data-value="5"></i><b>(5)</b>
        task_id='spark_pi_submit',
        namespace="default",
        application_file="pyspark-pi.yaml",
        do_xcom_push=True,
        dag=dag,
    )

    t2 = SparkKubernetesSensor(  <i class="conum" data-value="6"></i><b>(6)</b>
        task_id='spark_pi_monitor',
        namespace="default",
        application_name="{{ task_instance.xcom_pull(task_ids='spark_pi_submit')['metadata']['name'] }}",
        poke_interval=5,
        dag=dag,
    )

    t1 &gt;&gt; t2  <i class="conum" data-value="7"></i><b>(7)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>the wrapper class used for calling the job via <code>KubernetesHook</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>the connection that created for in-cluster usage</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>the wrapper class used for monitoring the job via <code>KubernetesHook</code></td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>the start of the DAG code</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>the initial task to invoke the job</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>the subsequent task to monitor the job</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>the jobs are chained together in the correct order</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Once this DAG is <a href="#_mounting_dags">mounted</a> in the DAG folder it can be called and its progress viewed from within the Webserver UI:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/airflow_dag_graph.png" alt="Airflow Connections">
</div>
</div>
<div class="paragraph">
<p>Clicking on the "spark_pi_monitor" task and selecting the logs shows that the status of the job has been tracked by Airflow:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/airflow_dag_log.png" alt="Airflow Connections">
</div>
</div>
</div>
</div>
</div>
</article>
  </div>
</main>
    </div>
</div>
<footer class="footer">
</footer>
<script src="../../_/js/site.js"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
<script src="../../_/js/vendor/lunr.js"></script>
<script src="../../_/js/search-ui.js" id="search-ui-script" data-site-root-path="../.." data-snippet-length="100" data-stylesheet="../../_/css/search.css"></script>
<script async src="../../search-index.js"></script>
  </body>
</html>
